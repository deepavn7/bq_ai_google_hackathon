{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåç ESG & Financial Intelligence Platform\n",
        "## AI-Powered Analysis of Corporate Reports (ESG And Annual)\n",
        "\n",
        "**üéØ What this does:**\n",
        "- Automatically processes PDF reports from Google Cloud Storage\n",
        "- Uses Gemini 2.5 Pro to extract financial & ESG metrics\n",
        "- Generates forecasts using Google's TimesFM 2.0 model\n",
        "- Analyzes companies: Amgen, Novartis, Target\n",
        "\n",
        "**üìä Features:**\n",
        "- ‚úÖ Automated PDF processing from Cloud Storage\n",
        "- ‚úÖ AI-powered data extraction (Financial + ESG metrics)\n",
        "- ‚úÖ Revenue forecasting with TimesFM 2.0\n",
        "- ‚úÖ Multi-company comparative analysis\n",
        "\n",
        "---\n",
        "**üëÜ Click \"Runtime\" ‚Üí \"Run all\" to see the magic happen!**"
      ],
      "metadata": {
        "id": "B4mF9BKbVXq9"
      },
      "id": "B4mF9BKbVXq9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Setup & Authentication"
      ],
      "metadata": {
        "id": "KdGXBO2wqGdM"
      },
      "id": "KdGXBO2wqGdM"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üåü Welcome to the ESG & Financial Intelligence Platform!\")\n",
        "print(\"üîß Setting up environment...\")\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q bigframes google-cloud-bigquery plotly seaborn\n",
        "\n",
        "# Import libraries\n",
        "import bigframes.pandas as bpd\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"‚úÖ Authentication complete!\")\n",
        "print(\"‚úÖ Libraries installed!\")"
      ],
      "metadata": {
        "id": "MsdBozKaVcBV"
      },
      "id": "MsdBozKaVcBV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intializing Parameters"
      ],
      "metadata": {
        "id": "G8ZIpU_YqTKm"
      },
      "id": "G8ZIpU_YqTKm"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "PROJECT_LOCATION=\"US\"\n",
        "CLOUD_RES_CONN = \"ghack_conn\"\n",
        "QUALIFIED_CLOUD_RES_CONN = f\"{PROJECT_ID}.{PROJECT_LOCATION}.{CLOUD_RES_CONN}\"\n",
        "\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "OBJ_TABLE_ID = \"all_reports_obj_table_metadata\"\n",
        "RAW_TABLE_ID=\"all_reports_ai_text_raw\"\n",
        "RAW2_TABLE_ID=\"all_reports_ai_text_raw2\"\n",
        "CURATED_TABLE_ID=\"all_reports_ai_text_curated\"\n",
        "FINAL_TABLE_ID=\"all_reports_ai_text_final\"\n",
        "FORECAST_TABLE_ID=\"all_reports_forecast\"\n",
        "\n",
        "QUALIFIED_OBJ_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{OBJ_TABLE_ID}\"\n",
        "QUALIFIED_RAW_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{RAW_TABLE_ID}\"\n",
        "QUALIFIED_RAW2_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{RAW2_TABLE_ID}\"\n",
        "\n",
        "QUALIFIED_CURATED_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{CURATED_TABLE_ID}\"\n",
        "QUALIFIED_FINAL_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FINAL_TABLE_ID}\"\n",
        "QUALIFIED_FORECAST_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FORECAST_TABLE_ID}\"\n",
        "\n",
        "MODEL_ENDPOINT=\"gemini-2.5-pro\"\n",
        "MODEL_NAME=\"gemini_model_25pro\"\n",
        "QUALIFIED_MODEL_ID=f\"{PROJECT_ID}.{DATASET_ID}.{MODEL_NAME}\"\n",
        "\n",
        "DATA_FILES_PATH=\"gs://report_insights\""
      ],
      "metadata": {
        "id": "j9wXa542JAad"
      },
      "id": "j9wXa542JAad",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèóÔ∏è Project Configuration"
      ],
      "metadata": {
        "id": "xEZ9AjxmqYPW"
      },
      "id": "xEZ9AjxmqYPW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "import getpass\n",
        "\n",
        "# Get project configuration\n",
        "try:\n",
        "    PROJECT_ID = userdata.get('GOOGLE_CLOUD_PROJECT')\n",
        "    print(f\"‚úÖ Using project from secrets: {PROJECT_ID}\")\n",
        "except:\n",
        "    PROJECT_ID = getpass.getpass(\"üîë Enter your Google Cloud Project ID: \")\n",
        "\n",
        "# Configure BigFrames\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = \"US\"\n",
        "\n",
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"‚úÖ Project configured: {PROJECT_ID}\")\n",
        "print(\"‚úÖ BigFrames ready for action!\")"
      ],
      "metadata": {
        "id": "Jq2mXY6ZWC29"
      },
      "id": "Jq2mXY6ZWC29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Create Cloud Resource Connection"
      ],
      "metadata": {
        "id": "ibVYprE2qbYa"
      },
      "id": "ibVYprE2qbYa"
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --connection_type=CLOUD_RESOURCE \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN}"
      ],
      "metadata": {
        "id": "-5dp4Ss5BmI_"
      },
      "id": "-5dp4Ss5BmI_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Service Account associated with the Cloud Res Connection"
      ],
      "metadata": {
        "id": "TJA-cM8fqkea"
      },
      "id": "TJA-cM8fqkea"
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCT = !bq show --format=prettyjson \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN} | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[0]  # first (and only) line\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "Br8HeQf8COGv"
      },
      "id": "Br8HeQf8COGv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Give the below roles to the Conn Service Account:\n",
        "  * objectViewer and  \n",
        "  * aiplatformUser\n",
        "\n"
      ],
      "metadata": {
        "id": "wLTg-1olqrA5"
      },
      "id": "wLTg-1olqrA5"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Use $SERVICE_ACCT_EMAIL so the Python variable expands in the shell\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/storage.objectViewer\" \\\n",
        "    --format=none\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/aiplatform.user\" \\\n",
        "    --format=none\n",
        "\n",
        "# Wait ~60 seconds for IAM updates to propagate\n",
        "time.sleep(60)"
      ],
      "metadata": {
        "id": "TOoTQl_iDVNQ"
      },
      "id": "TOoTQl_iDVNQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Gemini Model"
      ],
      "metadata": {
        "id": "zoGn5y3prEO1"
      },
      "id": "zoGn5y3prEO1"
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Step 0a: Create Gemini 2.5 Pro Model\n",
        "print(\"ü§ñ Creating Gemini 2.5 Pro model...\")\n",
        "\n",
        "create_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{QUALIFIED_MODEL_ID}`\n",
        "REMOTE WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (ENDPOINT = '{MODEL_ENDPOINT}');\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_model_sql)\n",
        "    job.result()\n",
        "    print(\"üéâ Gemini 2.5 Pro model created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Model creation issue: {e}\")"
      ],
      "metadata": {
        "id": "8H-B2sKyNRYI"
      },
      "id": "8H-B2sKyNRYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÅ Create Object Table for PDF Reports"
      ],
      "metadata": {
        "id": "uN-WN3hwrJQO"
      },
      "id": "uN-WN3hwrJQO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(f\"üìÅ Creating external table(Object Table): '{OBJ_TABLE_ID}' for PDF reports...\")\n",
        "\n",
        "create_external_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (\n",
        "  object_metadata = 'SIMPLE',\n",
        "  uris = ['{DATA_FILES_PATH}/*']\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_external_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ External table created successfully!\")\n",
        "\n",
        "    # Check what files we have\n",
        "    check_files_sql = f\"SELECT uri, size FROM `{QUALIFIED_OBJ_TABLE_ID}`  \"\n",
        "    files_df = bpd.read_gbq(check_files_sql)\n",
        "    print(f\"üìÑ Found {len(files_df)} files in storage\")\n",
        "    print(\"Sample files:\")\n",
        "    print(files_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Note: {e}\")\n",
        "    print(\"   Make sure your GCS bucket and connection are set up correctly\")"
      ],
      "metadata": {
        "id": "7YQ_Q-LjIF0U"
      },
      "id": "7YQ_Q-LjIF0U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Extract Financial & ESG Data using AI - Using ML.GENERATE_TEXT"
      ],
      "metadata": {
        "id": "vyuEomOKrU84"
      },
      "id": "vyuEomOKrU84"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üß† Processing PDFs with Gemini 2.5 Pro...\")\n",
        "print(\"   This analyzes Amgen, Target, and Novartis reports...\")\n",
        "\n",
        "generate_text_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_RAW_TABLE_ID}` AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "    TABLE `{QUALIFIED_OBJ_TABLE_ID}`,\n",
        "    STRUCT(\n",
        "      '''\n",
        "      You are an expert ESG and Financial analyst. Use only the information provided in the document to answer.\n",
        "      Fetch Financial and Sustainability Details including tabular and image data for each PDF.\n",
        "      ''' AS prompt,\n",
        "\n",
        "      0 AS temperature,\n",
        "      8092 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "WHERE uri like '%amgen%' or uri like '%target%' or  uri like '%novartis%'\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Processing... This may take 2-3 minutes\")\n",
        "    job = client.query(generate_text_sql)\n",
        "    job.result()\n",
        "\n",
        "    # Check results\n",
        "    check_sql = f\"SELECT COUNT(*) as processed_files FROM `{QUALIFIED_RAW_TABLE_ID}`\"\n",
        "    result = client.query(check_sql).result()\n",
        "    count = list(result)[0][0]\n",
        "    print(f\"‚úÖ Successfully processed {count} files!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Processing issue: {e}\")"
      ],
      "metadata": {
        "id": "BHfkpWRwZ7Lw"
      },
      "id": "BHfkpWRwZ7Lw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Extract Financial & ESG Data using AI - Using AI.GENERATE"
      ],
      "metadata": {
        "id": "hNh4AXmOv2UI"
      },
      "id": "hNh4AXmOv2UI"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üß† Processing PDFs with Gemini 2.5 Pro...\")\n",
        "print(\"   This analyzes Amgen, Target, and Novartis reports...\")\n",
        "\n",
        "generate_text_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_RAW_TABLE_ID}` AS\n",
        "SELECT\n",
        "  uri,\n",
        "  AI.GENERATE(\n",
        "    CONCAT(\n",
        "      \"Open and Read the PDF: \",\n",
        "      JSON_VALUE(\n",
        "        OBJ.GET_ACCESS_URL(\n",
        "          OBJ.MAKE_REF(uri, '{QUALIFIED_CLOUD_RES_CONN}'),\n",
        "          'r'\n",
        "        ),\n",
        "        '$.access_urls.read_url'\n",
        "      ),\n",
        "  \"You are an expert ESG and Financial analyst. Use only the information provided in the document to answer.\\n\",\n",
        "  \"Fetch Detailed Financial and Sustainability information from the entire document including tabular and image data for each PDF:\\n\"\n",
        "\n",
        "\n",
        "    ),\n",
        "    connection_id => '{QUALIFIED_CLOUD_RES_CONN}',\n",
        "    endpoint => '{MODEL_ENDPOINT}',\n",
        "    output_schema => 'uri STRING, response_text STRING'\n",
        "  ).response_text AS response_text\n",
        "FROM `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "WHERE uri LIKE '%amgen%' OR uri LIKE '%target%' OR uri LIKE '%novartis%';\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Processing... This may take 2-3 minutes\")\n",
        "    job = client.query(generate_text_sql)\n",
        "    job.result()\n",
        "\n",
        "    # Check results\n",
        "    check_sql = f\"SELECT COUNT(*) as processed_files FROM `{QUALIFIED_RAW_TABLE_ID}`\"\n",
        "    result = client.query(check_sql).result()\n",
        "    count = list(result)[0][0]\n",
        "    print(f\"‚úÖ Successfully processed {count} files!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Processing issue: {e}\")"
      ],
      "metadata": {
        "id": "WpdJJYc_uVZ7",
        "outputId": "0e1c03a2-6e1f-4cd1-ad93-8c56c9024696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WpdJJYc_uVZ7",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Processing PDFs with Gemini 2.5 Pro...\n",
            "   This analyzes Amgen, Target, and Novartis reports...\n",
            "‚è≥ Processing... This may take 2-3 minutes\n",
            "‚ö†Ô∏è  Processing issue: 400 Syntax error: Unclosed string literal at [7:7]; reason: invalidQuery, location: query, message: Syntax error: Unclosed string literal at [7:7]\n",
            "\n",
            "Location: US\n",
            "Job ID: 7aa7a650-bc9e-4707-8dc6-0245385df8b5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßπ Extract Clean Text Response"
      ],
      "metadata": {
        "id": "Ct2UPyXMrnbD"
      },
      "id": "Ct2UPyXMrnbD"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üßπ Cleaning and extracting response text...\")\n",
        "\n",
        "curate_results_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_CURATED_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "  ARRAY_TO_STRING(\n",
        "    ARRAY(\n",
        "      SELECT JSON_VALUE(part, '$.text')\n",
        "      FROM UNNEST(JSON_QUERY_ARRAY(\n",
        "        JSON_QUERY(ml_generate_text_result, '$.candidates[0].content.parts')\n",
        "      )) AS part\n",
        "    ),\n",
        "    ''\n",
        "  ) AS response_text\n",
        "FROM\n",
        "  `{QUALIFIED_RAW_TABLE_ID}`;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(curate_results_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Response text extracted and cleaned!\")\n",
        "\n",
        "    # Show sample of extracted text\n",
        "    sample_sql = f\"\"\"\n",
        "    SELECT uri, LEFT(response_text, 200) as sample_text\n",
        "    FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "    LIMIT 3\n",
        "    \"\"\"\n",
        "    sample_df = bpd.read_gbq(sample_sql)\n",
        "    print(\"\\nüìù Sample extracted text:\")\n",
        "    for _, row in sample_df.iterrows():\n",
        "        print(f\"File: {row['uri']}\")\n",
        "        print(f\"Text: {row['sample_text']}...\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Text extraction issue: {e}\")"
      ],
      "metadata": {
        "id": "_hLB42ZHW1mV"
      },
      "id": "_hLB42ZHW1mV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Extract Structured Financial & ESG Metrics"
      ],
      "metadata": {
        "id": "7u1iCJairu6y"
      },
      "id": "7u1iCJairu6y"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üìä Generating structured financial and ESG metrics...\")\n",
        "\n",
        "generate_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FINAL_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "    DATE(CAST(fiscal_year AS STRING) || \"-01-01\") AS fiscal_year_date,\n",
        "    CASE\n",
        "        WHEN uri LIKE '%amgen%' THEN 'Amgen'\n",
        "        WHEN uri LIKE '%novartis%' THEN 'Novartis'\n",
        "        WHEN uri LIKE '%target%' THEN 'Target'\n",
        "    END as company_name_formatted\n",
        "FROM (\n",
        "    SELECT *\n",
        "    FROM AI.GENERATE_TABLE(\n",
        "        MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "        (\n",
        "            SELECT CONCAT(\n",
        "                \"You are an expert financial analyst and ESG/Climate analyst. Extract all financial metrics and sustainability metrics and KPIs from the provided text into structured data. \",\n",
        "                \"For Annual reports, focus on getting the financial metrics. And for Sustainability reports focus on getting ESG metrics. \",\n",
        "                \"Normalize numbers by removing commas, spaces, or symbols. \",\n",
        "                \"Only include actual numerical financial data. \",\n",
        "                \"TEXT: \",\n",
        "                response_text\n",
        "            ) AS prompt,\n",
        "            response_text as extracted_text,\n",
        "            uri AS uri\n",
        "        FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "        ),\n",
        "        STRUCT(\n",
        "            'uris STRING, report_type STRING, company_name STRING, fiscal_year INT64, revenue_millions FLOAT64, net_income_millions FLOAT64, total_assets_millions FLOAT64, total_liabilities_millions FLOAT64, equity_millions FLOAT64, eps_basic FLOAT64, eps_diluted FLOAT64, dividends_per_share FLOAT64, employee_count INT64, business_segments ARRAY<STRING>, total_ghg_emissions FLOAT64, scope_1_ghg_emissions FLOAT64, scope_2_ghg_emissions FLOAT64, scope_3_ghg_emissions FLOAT64, carbon_intensity FLOAT64, energy_consumption FLOAT64, renewable_energy_usage FLOAT64, water_consumption FLOAT64, waste_generated FLOAT64, waste_recycled FLOAT64, sustainable_financing FLOAT64, reporting_period STRING, page_references ARRAY<STRING>, contexts ARRAY<STRING>, verbatim_quotes ARRAY<STRING>'\n",
        "            AS output_schema,\n",
        "            8192 AS max_output_tokens,\n",
        "            0 AS temperature\n",
        "        )\n",
        "    ) t\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Structuring data... This may take 3-4 minutes\")\n",
        "    job = client.query(generate_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Structured metrics extracted successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Table generation issue: {e}\")"
      ],
      "metadata": {
        "id": "2QOTj5J1XUW4"
      },
      "id": "2QOTj5J1XUW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÆ Revenue Forecasting with TimesFM 2.0"
      ],
      "metadata": {
        "id": "QAwsY7BWr0l1"
      },
      "id": "QAwsY7BWr0l1"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"üîÆ Generating revenue forecasts with TimesFM 2.0...\")\n",
        "\n",
        "forecast_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FORECAST_TABLE_ID}` AS\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  AI.FORECAST(\n",
        "    TABLE `{QUALIFIED_FINAL_TABLE_ID}`,\n",
        "    data_col => 'revenue_millions',\n",
        "    timestamp_col => 'fiscal_year_date',\n",
        "    model => 'TimesFM 2.0',\n",
        "    id_cols => ['company_name_formatted'],\n",
        "    horizon => 5,\n",
        "    confidence_level => .95\n",
        "  )\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚è≥ Forecasting...\")\n",
        "job = client.query(forecast_sql)\n",
        "job.result()\n",
        "print(\"‚úÖ Forecast table created successfully!\")"
      ],
      "metadata": {
        "id": "QjS1OIZwmIZg"
      },
      "id": "QjS1OIZwmIZg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# from google.cloud import bigquery\n",
        "\n",
        "# PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "# DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "# TABLE_ID = \"all_reports_annual_esg\"\n",
        "\n",
        "# # Step 0: Fetch file list from GitHub\n",
        "# url = \"https://api.github.com/repos/intellitrend-global/google_hackathon_bq_ai/contents/annual_esg_reports\"\n",
        "# response = requests.get(url)\n",
        "# files = response.json()\n",
        "\n",
        "# pdf_files = [(f[\"name\"], f[\"download_url\"]) for f in files if f[\"name\"].endswith(\".pdf\")]\n",
        "\n",
        "# print(\"üìÑ Found PDF files on GitHub:\")\n",
        "# for name, link in pdf_files:\n",
        "#     print(f\"   {name} -> {link}\")\n",
        "\n",
        "# # Step 1: Initialize BigQuery client\n",
        "# client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# # Step 2: Ensure dataset exists (create if not)\n",
        "# dataset_ref = bigquery.DatasetReference(PROJECT_ID, DATASET_ID)\n",
        "# try:\n",
        "#     client.get_dataset(dataset_ref)  # Check if it exists\n",
        "#     print(f\"‚úÖ Dataset {DATASET_ID} already exists\")\n",
        "# except Exception:\n",
        "#     dataset = bigquery.Dataset(dataset_ref)\n",
        "#     dataset.location = \"US\"\n",
        "#     client.create_dataset(dataset, timeout=30)\n",
        "#     print(f\"üì¶ Created dataset {DATASET_ID}\")\n",
        "\n",
        "# # Step 3: Define schema\n",
        "# schema = [\n",
        "#     bigquery.SchemaField(\"filename\", \"STRING\"),\n",
        "#     bigquery.SchemaField(\"uri\", \"STRING\"),\n",
        "# ]\n",
        "\n",
        "# # Step 4: Prepare rows\n",
        "# rows = [{\"filename\": name, \"uri\": link} for name, link in pdf_files]\n",
        "\n",
        "# # Step 5: Load into BigQuery\n",
        "# job_config = bigquery.LoadJobConfig(schema=schema, write_disposition=\"WRITE_TRUNCATE\")\n",
        "# table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# job = client.load_table_from_json(rows, table_ref, job_config=job_config)\n",
        "# job.result()\n",
        "\n",
        "# print(f\"‚úÖ Table {table_ref} created/updated with {len(pdf_files)} GitHub files\")\n"
      ],
      "metadata": {
        "id": "xNskNaElWO_1"
      },
      "id": "xNskNaElWO_1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}