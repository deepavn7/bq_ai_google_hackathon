{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ ESG & Financial Intelligence Platform\n",
        "## AI-Powered Analysis of Corporate Reports (ESG And Annual)\n",
        "\n",
        "**ðŸŽ¯ What this does:**\n",
        "- Automatically processes PDF reports from Google Cloud Storage\n",
        "- Uses Gemini 2.5 Pro to extract financial & ESG metrics\n",
        "- Generates forecasts using Google's TimesFM 2.0 model\n",
        "- Analyzes companies: Amgen, Novartis, Target\n",
        "\n",
        "**ðŸ“Š Features:**\n",
        "- âœ… Automated PDF processing from Cloud Storage\n",
        "- âœ… AI-powered data extraction (Financial + ESG metrics)\n",
        "- âœ… Revenue forecasting with TimesFM 2.0\n",
        "- âœ… Multi-company comparative analysis\n",
        "\n",
        "---\n",
        "**ðŸ‘† Click \"Runtime\" â†’ \"Run all\" to see the magic happen!**"
      ],
      "metadata": {
        "id": "B4mF9BKbVXq9"
      },
      "id": "B4mF9BKbVXq9"
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸš€ Setup & Authentication\n",
        "print(\"ðŸŒŸ Welcome to the ESG & Financial Intelligence Platform!\")\n",
        "print(\"ðŸ”§ Setting up environment...\")\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q bigframes google-cloud-bigquery plotly seaborn\n",
        "\n",
        "# Import libraries\n",
        "import bigframes.pandas as bpd\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"âœ… Authentication complete!\")\n",
        "print(\"âœ… Libraries installed!\")"
      ],
      "metadata": {
        "id": "MsdBozKaVcBV"
      },
      "id": "MsdBozKaVcBV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ—ï¸ Project Configuration\n",
        "from google.colab import userdata\n",
        "import getpass\n",
        "\n",
        "# Get project configuration\n",
        "try:\n",
        "    PROJECT_ID = userdata.get('GOOGLE_CLOUD_PROJECT')\n",
        "    print(f\"âœ… Using project from secrets: {PROJECT_ID}\")\n",
        "except:\n",
        "    PROJECT_ID = getpass.getpass(\"ðŸ”‘ Enter your Google Cloud Project ID: \")\n",
        "\n",
        "# Configure BigFrames\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = \"US\"\n",
        "\n",
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"âœ… Project configured: {PROJECT_ID}\")\n",
        "print(\"âœ… BigFrames ready for action!\")"
      ],
      "metadata": {
        "id": "Jq2mXY6ZWC29"
      },
      "id": "Jq2mXY6ZWC29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "PROJECT_LOCATION=\"US\"\n",
        "CLOUD_RES_CONN = \"ghack_conn\"\n",
        "QUALIFIED_CLOUD_RES_CONN = f\"{PROJECT_ID}.{PROJECT_LOCATION}.{CLOUD_RES_CONN}\"\n",
        "\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "OBJ_TABLE_ID = \"all_reports_obj_table_metadata\"\n",
        "QUALIFIED_OBJ_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{OBJ_TABLE_ID}\""
      ],
      "metadata": {
        "id": "j9wXa542JAad"
      },
      "id": "j9wXa542JAad",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --connection_type=CLOUD_RESOURCE \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN}"
      ],
      "metadata": {
        "id": "-5dp4Ss5BmI_",
        "outputId": "ae03db2d-b4f2-4868-f90d-71c09562f3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-5dp4Ss5BmI_",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery error in mk operation: Already Exists: Connection\n",
            "projects/573553606303/locations/us/connections/ghack_conn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCT = !bq show --format=prettyjson \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN} | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[0]  # first (and only) line\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "Br8HeQf8COGv",
        "outputId": "a2f14780-72d7-4b00-efa1-c569b4ce40a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Br8HeQf8COGv",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bqcx-573553606303-2s0n@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Use $SERVICE_ACCT_EMAIL so the Python variable expands in the shell\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/storage.objectViewer\" \\\n",
        "    --format=none\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/aiplatform.user\" \\\n",
        "    --format=none\n",
        "\n",
        "# Wait ~60 seconds for IAM updates to propagate\n",
        "time.sleep(60)"
      ],
      "metadata": {
        "id": "TOoTQl_iDVNQ",
        "outputId": "283fdcf8-6adc-4dd2-f54b-107246f405f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TOoTQl_iDVNQ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated IAM policy for project [intellitrend-project-dev].\n",
            "Updated IAM policy for project [intellitrend-project-dev].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "OBJ_TABLE_ID=\"all_reports_obj_table_metadata\"\n",
        "QUALIFIED_OBJ_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{OBJ_TABLE_ID}\"\n",
        "\n",
        "DATA_FILES_PATH=\"gs://report_insights\""
      ],
      "metadata": {
        "id": "Xwm9-kE_AkC2"
      },
      "id": "Xwm9-kE_AkC2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“ Step 0: Create External Table for PDF Reports\n",
        "\n",
        "print(f\"ðŸ“ Creating external table(Object Table) {OBJ_TABLE_ID} for PDF reports...\")\n",
        "\n",
        "create_external_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (\n",
        "  object_metadata = 'SIMPLE',\n",
        "  uris = ['{DATA_FILES_PATH}/*']\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_external_table_sql)\n",
        "    job.result()\n",
        "    print(\"âœ… External table created successfully!\")\n",
        "\n",
        "    # Check what files we have\n",
        "    check_files_sql = f\"SELECT uri, size FROM `{QUALIFIED_OBJ_TABLE_ID}` LIMIT 10\"\n",
        "    files_df = bpd.read_gbq(check_files_sql)\n",
        "    print(f\"ðŸ“„ Found {len(files_df)} files in storage\")\n",
        "    print(\"Sample files:\")\n",
        "    print(files_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Note: {e}\")\n",
        "    print(\"   Make sure your GCS bucket and connection are set up correctly\")"
      ],
      "metadata": {
        "id": "7YQ_Q-LjIF0U"
      },
      "id": "7YQ_Q-LjIF0U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§  Step 1: Extract Financial & ESG Data using AI\n",
        "print(\"ðŸ§  Processing PDFs with Gemini 2.5 Pro (direct call, no model creation)...\")\n",
        "print(\"   This analyzes Amgen, Target, and Novartis reports...\")\n",
        "\n",
        "generate_text_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{PROJECT_ID}.db_reports_insights_annual_esg.all_reports_results_raw_annual_esg` AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  AI.GENERATE(\n",
        "    MODEL `gemini-2.5-pro`,\n",
        "    TABLE `{PROJECT_ID}.db_reports_insights_annual_esg.all_reports_annual_esg`,\n",
        "    STRUCT(\n",
        "      '''\n",
        "You are an expert ESG and Financial analyst. Use only the information provided in the document to answer.\n",
        "Fetch Financial and Sustainability Details including tabular and image data for each PDF.\n",
        "      ''' AS prompt,\n",
        "      0 AS temperature,\n",
        "      8092 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "WHERE uri LIKE '%amgen%' OR uri LIKE '%target%' OR uri LIKE '%novartis%'\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"â³ Processing... This may take 2-3 minutes\")\n",
        "    job = client.query(generate_text_sql)\n",
        "    job.result()\n",
        "\n",
        "    # Check results\n",
        "    check_sql = f\"\"\"\n",
        "        SELECT COUNT(*) AS processed_files\n",
        "        FROM `{PROJECT_ID}.db_reports_insights_annual_esg.all_reports_results_raw_annual_esg`\n",
        "    \"\"\"\n",
        "    result = client.query(check_sql).result()\n",
        "    count = list(result)[0][0]\n",
        "    print(f\"âœ… Successfully processed {count} files!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Processing issue: {e}\")\n"
      ],
      "metadata": {
        "id": "BHfkpWRwZ7Lw"
      },
      "id": "BHfkpWRwZ7Lw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from google.cloud import bigquery\n",
        "\n",
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "TABLE_ID = \"all_reports_annual_esg\"\n",
        "\n",
        "# Step 0: Fetch file list from GitHub\n",
        "url = \"https://api.github.com/repos/intellitrend-global/google_hackathon_bq_ai/contents/annual_esg_reports\"\n",
        "response = requests.get(url)\n",
        "files = response.json()\n",
        "\n",
        "pdf_files = [(f[\"name\"], f[\"download_url\"]) for f in files if f[\"name\"].endswith(\".pdf\")]\n",
        "\n",
        "print(\"ðŸ“„ Found PDF files on GitHub:\")\n",
        "for name, link in pdf_files:\n",
        "    print(f\"   {name} -> {link}\")\n",
        "\n",
        "# Step 1: Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Step 2: Ensure dataset exists (create if not)\n",
        "dataset_ref = bigquery.DatasetReference(PROJECT_ID, DATASET_ID)\n",
        "try:\n",
        "    client.get_dataset(dataset_ref)  # Check if it exists\n",
        "    print(f\"âœ… Dataset {DATASET_ID} already exists\")\n",
        "except Exception:\n",
        "    dataset = bigquery.Dataset(dataset_ref)\n",
        "    dataset.location = \"US\"\n",
        "    client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"ðŸ“¦ Created dataset {DATASET_ID}\")\n",
        "\n",
        "# Step 3: Define schema\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"filename\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"uri\", \"STRING\"),\n",
        "]\n",
        "\n",
        "# Step 4: Prepare rows\n",
        "rows = [{\"filename\": name, \"uri\": link} for name, link in pdf_files]\n",
        "\n",
        "# Step 5: Load into BigQuery\n",
        "job_config = bigquery.LoadJobConfig(schema=schema, write_disposition=\"WRITE_TRUNCATE\")\n",
        "table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "job = client.load_table_from_json(rows, table_ref, job_config=job_config)\n",
        "job.result()\n",
        "\n",
        "print(f\"âœ… Table {table_ref} created/updated with {len(pdf_files)} GitHub files\")\n"
      ],
      "metadata": {
        "id": "xNskNaElWO_1"
      },
      "id": "xNskNaElWO_1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}