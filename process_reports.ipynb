{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåç ESG & Financial Intelligence Platform\n",
        "## AI-Powered Analysis of Corporate Reports (ESG And Annual)\n",
        "\n",
        "**üéØ What this does:**\n",
        "- Automatically processes PDF reports from Google Cloud Storage\n",
        "- Uses Gemini 2.5 Pro to extract financial & ESG metrics\n",
        "- Generates forecasts using Google's TimesFM 2.0 model\n",
        "- Analyzes companies: Amgen, Novartis, Target\n",
        "\n",
        "**üìä Features:**\n",
        "- ‚úÖ Automated PDF processing from Cloud Storage\n",
        "- ‚úÖ AI-powered data extraction (Financial + ESG metrics)\n",
        "- ‚úÖ Revenue forecasting with TimesFM 2.0\n",
        "- ‚úÖ Multi-company comparative analysis\n",
        "\n",
        "---\n",
        "**üëÜ Click \"Runtime\" ‚Üí \"Run all\" to see the magic happen!**"
      ],
      "metadata": {
        "id": "B4mF9BKbVXq9"
      },
      "id": "B4mF9BKbVXq9"
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Setup & Authentication\n",
        "print(\"üåü Welcome to the ESG & Financial Intelligence Platform!\")\n",
        "print(\"üîß Setting up environment...\")\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q bigframes google-cloud-bigquery plotly seaborn\n",
        "\n",
        "# Import libraries\n",
        "import bigframes.pandas as bpd\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"‚úÖ Authentication complete!\")\n",
        "print(\"‚úÖ Libraries installed!\")"
      ],
      "metadata": {
        "id": "MsdBozKaVcBV",
        "outputId": "56a37398-c6a9-4b4d-a3e9-a210784d9a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MsdBozKaVcBV",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåü Welcome to the ESG & Financial Intelligence Platform!\n",
            "üîß Setting up environment...\n",
            "‚úÖ Authentication complete!\n",
            "‚úÖ Libraries installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üèóÔ∏è Project Configuration\n",
        "from google.colab import userdata\n",
        "import getpass\n",
        "\n",
        "# Get project configuration\n",
        "try:\n",
        "    PROJECT_ID = userdata.get('GOOGLE_CLOUD_PROJECT')\n",
        "    print(f\"‚úÖ Using project from secrets: {PROJECT_ID}\")\n",
        "except:\n",
        "    PROJECT_ID = getpass.getpass(\"üîë Enter your Google Cloud Project ID: \")\n",
        "\n",
        "# Configure BigFrames\n",
        "bpd.options.bigquery.project = PROJECT_ID\n",
        "bpd.options.bigquery.location = \"US\"\n",
        "\n",
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "print(f\"‚úÖ Project configured: {PROJECT_ID}\")\n",
        "print(\"‚úÖ BigFrames ready for action!\")"
      ],
      "metadata": {
        "id": "Jq2mXY6ZWC29",
        "outputId": "3a59f204-655f-49f5-894d-47062b04e1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Jq2mXY6ZWC29",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Enter your Google Cloud Project ID: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Project configured: intellitrend-project-dev\n",
            "‚úÖ BigFrames ready for action!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "PROJECT_LOCATION=\"US\"\n",
        "CLOUD_RES_CONN = \"ghack_conn\"\n",
        "QUALIFIED_CLOUD_RES_CONN = f\"{PROJECT_ID}.{PROJECT_LOCATION}.{CLOUD_RES_CONN}\"\n",
        "\n",
        "DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "OBJ_TABLE_ID = \"all_reports_obj_table_metadata\"\n",
        "RAW_TABLE_ID=\"all_reports_ai_text_raw\"\n",
        "CURATED_TABLE_ID=\"all_reports_ai_text_curated\"\n",
        "FINAL_TABLE_ID=\"all_reports_ai_text_final\"\n",
        "FORECAST_TABLE_ID=\"all_reports_forecast\"\n",
        "\n",
        "QUALIFIED_OBJ_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{OBJ_TABLE_ID}\"\n",
        "QUALIFIED_RAW_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{RAW_TABLE_ID}\"\n",
        "QUALIFIED_CURATED_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{CURATED_TABLE_ID}\"\n",
        "QUALIFIED_FINAL_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FINAL_TABLE_ID}\"\n",
        "QUALIFIED_FORECAST_TABLE_ID= f\"{PROJECT_ID}.{DATASET_ID}.{FORECAST_TABLE_ID}\"\n",
        "\n",
        "MODEL_ENDPOINT=\"gemini-2.5-pro\"\n",
        "MODEL_NAME=\"gemini_model_25pro\"\n",
        "QUALIFIED_MODEL_ID=f\"{PROJECT_ID}.{DATASET_ID}.{MODEL_NAME}\"\n",
        "\n",
        "DATA_FILES_PATH=\"gs://report_insights\""
      ],
      "metadata": {
        "id": "j9wXa542JAad"
      },
      "id": "j9wXa542JAad",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bq mk \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --connection_type=CLOUD_RESOURCE \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN}"
      ],
      "metadata": {
        "id": "-5dp4Ss5BmI_",
        "outputId": "254102e2-9135-40ac-eabf-3d8fc7644fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-5dp4Ss5BmI_",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery error in mk operation: Already Exists: Connection\n",
            "projects/573553606303/locations/us/connections/ghack_conn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SERVICE_ACCT = !bq show --format=prettyjson \\\n",
        "  --connection \\\n",
        "  --project_id={PROJECT_ID} \\\n",
        "  --location={PROJECT_LOCATION} \\\n",
        "  {CLOUD_RES_CONN} | grep \"serviceAccountId\" | cut -d '\"' -f 4\n",
        "\n",
        "SERVICE_ACCT_EMAIL = SERVICE_ACCT[0]  # first (and only) line\n",
        "print(SERVICE_ACCT_EMAIL)"
      ],
      "metadata": {
        "id": "Br8HeQf8COGv",
        "outputId": "9a4832ef-3d1a-41b1-8572-5f1556ae8f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Br8HeQf8COGv",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bqcx-573553606303-2s0n@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Use $SERVICE_ACCT_EMAIL so the Python variable expands in the shell\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/storage.objectViewer\" \\\n",
        "    --format=none\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} \\\n",
        "    --member=\"serviceAccount:$SERVICE_ACCT_EMAIL\" \\\n",
        "    --role=\"roles/aiplatform.user\" \\\n",
        "    --format=none\n",
        "\n",
        "# Wait ~60 seconds for IAM updates to propagate\n",
        "time.sleep(60)"
      ],
      "metadata": {
        "id": "TOoTQl_iDVNQ",
        "outputId": "062d9a38-cafd-4f17-995b-835ac647b247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TOoTQl_iDVNQ",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated IAM policy for project [intellitrend-project-dev].\n",
            "Updated IAM policy for project [intellitrend-project-dev].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ü§ñ Step 0a: Create Gemini 2.5 Pro Model\n",
        "print(\"ü§ñ Creating Gemini 2.5 Pro model...\")\n",
        "\n",
        "create_model_sql = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{QUALIFIED_MODEL_ID}`\n",
        "REMOTE WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (ENDPOINT = '{MODEL_ENDPOINT}');\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_model_sql)\n",
        "    job.result()\n",
        "    print(\"üéâ Gemini 2.5 Pro model created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Model creation issue: {e}\")"
      ],
      "metadata": {
        "id": "8H-B2sKyNRYI",
        "outputId": "a87d86e0-5ba7-4a28-80e4-070c8e714f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8H-B2sKyNRYI",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Creating Gemini 2.5 Pro model...\n",
            "üéâ Gemini 2.5 Pro model created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÅ Step 0: Create External Table for PDF Reports\n",
        "\n",
        "print(f\"üìÅ Creating external table(Object Table): '{OBJ_TABLE_ID}' for PDF reports...\")\n",
        "\n",
        "create_external_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE EXTERNAL TABLE `{QUALIFIED_OBJ_TABLE_ID}`\n",
        "WITH CONNECTION `{QUALIFIED_CLOUD_RES_CONN}`\n",
        "OPTIONS (\n",
        "  object_metadata = 'SIMPLE',\n",
        "  uris = ['{DATA_FILES_PATH}/*']\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(create_external_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ External table created successfully!\")\n",
        "\n",
        "    # Check what files we have\n",
        "    check_files_sql = f\"SELECT uri, size FROM `{QUALIFIED_OBJ_TABLE_ID}`  \"\n",
        "    files_df = bpd.read_gbq(check_files_sql)\n",
        "    print(f\"üìÑ Found {len(files_df)} files in storage\")\n",
        "    print(\"Sample files:\")\n",
        "    print(files_df.head())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Note: {e}\")\n",
        "    print(\"   Make sure your GCS bucket and connection are set up correctly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "7YQ_Q-LjIF0U",
        "outputId": "244094d7-d76d-453d-d808-529ffd3a05a4"
      },
      "id": "7YQ_Q-LjIF0U",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Creating external table(Object Table): 'all_reports_obj_table_metadata' for PDF reports...\n",
            "‚úÖ External table created successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 6dbb37e6-cbff-4acb-8ae3-ae81eb4e2a8d is DONE. 32.3 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=intellitrend-project-dev&j=bq:US:6dbb37e6-cbff-4acb-8ae3-ae81eb4e2a8d&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Found 79 files in storage\n",
            "Sample files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 9d7a09e5-0a7f-4fc7-92fd-e0886918483e is DONE. 5.8 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=intellitrend-project-dev&j=bq:US:9d7a09e5-0a7f-4fc7-92fd-e0886918483e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 uri      size\n",
            "0  gs://report_insights/wellsfargo/wellsfargo_sus...    642974\n",
            "1  gs://report_insights/lloyd/lloyd_sustainabilit...  10223646\n",
            "2  gs://report_insights/jpmorganchase/jpmorgancha...   7143472\n",
            "3  gs://report_insights/amgen/amgen_annualreport_...   8154936\n",
            "4  gs://report_insights/amgen/amgen_annualreport_...   3651904\n",
            "\n",
            "[5 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Step 1: Extract Financial & ESG Data using AI\n",
        "print(\"üß† Processing PDFs with Gemini 2.5 Pro...\")\n",
        "print(\"   This analyzes Amgen, Target, and Novartis reports...\")\n",
        "\n",
        "generate_text_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_RAW_TABLE_ID}` AS (\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.GENERATE_TEXT(\n",
        "    MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "    TABLE `{QUALIFIED_OBJ_TABLE_ID}`,\n",
        "    STRUCT(\n",
        "      '''\n",
        "      You are an expert ESG and Financial analyst. Use only the information provided in the document to answer.\n",
        "      Fetch Financial and Sustainability Details including tabular and image data for each PDF.\n",
        "      ''' AS prompt,\n",
        "\n",
        "      0 AS temperature,\n",
        "      8092 AS max_output_tokens\n",
        "    )\n",
        "  )\n",
        "WHERE uri like '%amgen%' or uri like '%target%' or  uri like '%novartis%'\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Processing... This may take 2-3 minutes\")\n",
        "    job = client.query(generate_text_sql)\n",
        "    job.result()\n",
        "\n",
        "    # Check results\n",
        "    check_sql = f\"SELECT COUNT(*) as processed_files FROM `{QUALIFIED_RAW_TABLE_ID}`\"\n",
        "    result = client.query(check_sql).result()\n",
        "    count = list(result)[0][0]\n",
        "    print(f\"‚úÖ Successfully processed {count} files!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Processing issue: {e}\")"
      ],
      "metadata": {
        "id": "BHfkpWRwZ7Lw",
        "outputId": "0805aeee-d2d6-4567-a9d5-eaddcf14fc97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BHfkpWRwZ7Lw",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Processing PDFs with Gemini 2.5 Pro...\n",
            "   This analyzes Amgen, Target, and Novartis reports...\n",
            "‚è≥ Processing... This may take 2-3 minutes\n",
            "‚úÖ Successfully processed 35 files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üßπ Step 2: Extract Clean Text Response\n",
        "print(\"üßπ Cleaning and extracting response text...\")\n",
        "\n",
        "curate_results_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_CURATED_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "  ARRAY_TO_STRING(\n",
        "    ARRAY(\n",
        "      SELECT JSON_VALUE(part, '$.text')\n",
        "      FROM UNNEST(JSON_QUERY_ARRAY(\n",
        "        JSON_QUERY(ml_generate_text_result, '$.candidates[0].content.parts')\n",
        "      )) AS part\n",
        "    ),\n",
        "    ''\n",
        "  ) AS response_text\n",
        "FROM\n",
        "  `{QUALIFIED_RAW_TABLE_ID}`;\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    job = client.query(curate_results_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Response text extracted and cleaned!\")\n",
        "\n",
        "    # Show sample of extracted text\n",
        "    sample_sql = f\"\"\"\n",
        "    SELECT uri, LEFT(response_text, 200) as sample_text\n",
        "    FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "    LIMIT 3\n",
        "    \"\"\"\n",
        "    sample_df = bpd.read_gbq(sample_sql)\n",
        "    print(\"\\nüìù Sample extracted text:\")\n",
        "    for _, row in sample_df.iterrows():\n",
        "        print(f\"File: {row['uri']}\")\n",
        "        print(f\"Text: {row['sample_text']}...\\n\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Text extraction issue: {e}\")"
      ],
      "metadata": {
        "id": "_hLB42ZHW1mV",
        "outputId": "d473860f-61c5-4059-ef9b-f40a307f9bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "id": "_hLB42ZHW1mV",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Cleaning and extracting response text...\n",
            "‚úÖ Response text extracted and cleaned!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 6099134e-a8f5-48ae-8304-fe75d2f9a463 is DONE. 285.9 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=intellitrend-project-dev&j=bq:US:6099134e-a8f5-48ae-8304-fe75d2f9a463&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìù Sample extracted text:\n",
            "File: gs://report_insights/amgen/amgen_sustainabilityreport_2024.pdf\n",
            "Text: Here are the financial and sustainability details from the Amgen 2024 Sustainability Highlights Report.\n",
            "\n",
            "### **Company Overview & Key Figures (Page 2)**\n",
            "\n",
            "The report outlines the company's performance ...\n",
            "\n",
            "File: gs://report_insights/amgen/amgen_sustainabilityreport_2023.pdf\n",
            "Text: This document is the **2023 Environmental, Social & Governance (ESG) Report** for **Amgen**. It details the company's progress and initiatives across its ESG framework for the period of January 1, 202...\n",
            "\n",
            "File: gs://report_insights/target/target_sustainabilityreport_2024.pdf\n",
            "Text: Of course. Here are the financial and sustainability details from the 2024 Sustainability and Governance Report.\n",
            "\n",
            "### **Page 1: Cover Page**\n",
            "\n",
            "*   **Title:** 2024 Sustainability and Governance Report\n",
            "*...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Step 3: Extract Structured Financial & ESG Metrics\n",
        "print(\"üìä Generating structured financial and ESG metrics...\")\n",
        "\n",
        "generate_table_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FINAL_TABLE_ID}` AS\n",
        "SELECT *,\n",
        "    DATE(CAST(fiscal_year AS STRING) || \"-01-01\") AS fiscal_year_date,\n",
        "    CASE\n",
        "        WHEN uri LIKE '%amgen%' THEN 'Amgen'\n",
        "        WHEN uri LIKE '%novartis%' THEN 'Novartis'\n",
        "        WHEN uri LIKE '%target%' THEN 'Target'\n",
        "    END as company_name_formatted\n",
        "FROM (\n",
        "    SELECT *\n",
        "    FROM AI.GENERATE_TABLE(\n",
        "        MODEL `{QUALIFIED_MODEL_ID}`,\n",
        "        (\n",
        "            SELECT CONCAT(\n",
        "                \"You are an expert financial analyst and ESG/Climate analyst. Extract all financial metrics and sustainability metrics and KPIs from the provided text into structured data. \",\n",
        "                \"For Annual reports, focus on getting the financial metrics. And for Sustainability reports focus on getting ESG metrics. \",\n",
        "                \"Normalize numbers by removing commas, spaces, or symbols. \",\n",
        "                \"Only include actual numerical financial data. \",\n",
        "                \"TEXT: \",\n",
        "                response_text\n",
        "            ) AS prompt,\n",
        "            response_text as extracted_text,\n",
        "            uri AS uri\n",
        "        FROM `{QUALIFIED_CURATED_TABLE_ID}`\n",
        "        ),\n",
        "        STRUCT(\n",
        "            'uris STRING, report_type STRING, company_name STRING, fiscal_year INT64, revenue_millions FLOAT64, net_income_millions FLOAT64, total_assets_millions FLOAT64, total_liabilities_millions FLOAT64, equity_millions FLOAT64, eps_basic FLOAT64, eps_diluted FLOAT64, dividends_per_share FLOAT64, employee_count INT64, business_segments ARRAY<STRING>, total_ghg_emissions FLOAT64, scope_1_ghg_emissions FLOAT64, scope_2_ghg_emissions FLOAT64, scope_3_ghg_emissions FLOAT64, carbon_intensity FLOAT64, energy_consumption FLOAT64, renewable_energy_usage FLOAT64, water_consumption FLOAT64, waste_generated FLOAT64, waste_recycled FLOAT64, sustainable_financing FLOAT64, reporting_period STRING, page_references ARRAY<STRING>, contexts ARRAY<STRING>, verbatim_quotes ARRAY<STRING>'\n",
        "            AS output_schema,\n",
        "            8192 AS max_output_tokens,\n",
        "            0 AS temperature\n",
        "        )\n",
        "    ) t\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    print(\"‚è≥ Structuring data... This may take 3-4 minutes\")\n",
        "    job = client.query(generate_table_sql)\n",
        "    job.result()\n",
        "    print(\"‚úÖ Structured metrics extracted successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Table generation issue: {e}\")"
      ],
      "metadata": {
        "id": "2QOTj5J1XUW4",
        "outputId": "c7446dd6-87af-4a49-f06b-5a0a6ed7ad67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2QOTj5J1XUW4",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Generating structured financial and ESG metrics...\n",
            "‚è≥ Structuring data... This may take 3-4 minutes\n",
            "‚úÖ Structured metrics extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÆ Step 5: Revenue Forecasting with TimesFM 2.0\n",
        "print(\"üîÆ Generating revenue forecasts with TimesFM 2.0...\")\n",
        "\n",
        "forecast_sql = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{QUALIFIED_FORECAST_TABLE_ID}` AS\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  AI.FORECAST(\n",
        "    TABLE `{QUALIFIED_FINAL_TABLE_ID}`,\n",
        "    data_col => 'revenue_millions',\n",
        "    timestamp_col => 'fiscal_year_date',\n",
        "    model => 'TimesFM 2.0',\n",
        "    id_cols => ['company_name_formatted'],\n",
        "    horizon => 5,\n",
        "    confidence_level => .95\n",
        "  )\n",
        "WHERE revenue_millions IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚è≥ Forecasting...\")\n",
        "job = client.query(forecast_sql)\n",
        "job.result()\n",
        "print(\"‚úÖ Forecast table created successfully!\")\n",
        "try:\n",
        "    print(\"‚è≥ Generating 5-year forecasts...\")\n",
        "    forecast_df = bpd.read_gbq(\"Select * from `{QUALIFIED_FORECAST_TABLE_ID}`;\").to_pandas()\n",
        "\n",
        "    # if not forecast_df.empty:\n",
        "    #     print(f\"‚úÖ Generated forecasts for {len(forecast_df)} data points\")\n",
        "\n",
        "    #     # Forecast visualization\n",
        "    #     fig = go.Figure()\n",
        "\n",
        "    #     companies = forecast_df['company_name_formatted'].unique()\n",
        "    #     colors = px.colors.qualitative.Pastel\n",
        "\n",
        "    #     for i, company in enumerate(companies):\n",
        "    #         company_data = forecast_df[forecast_df['company_name_formatted'] == company]\n",
        "    #         color = colors[i % len(colors)]\n",
        "\n",
        "    #         # Historical data\n",
        "    #         historical = company_data[company_data['forecast_timestamp'] <= company_data['fiscal_year_date'].max()]\n",
        "\n",
        "    #         # Forecast data\n",
        "    #         forecast = company_data[company_data['forecast_timestamp'] > company_data['fiscal_year_date'].max()]\n",
        "\n",
        "    #         # Historical line\n",
        "    #         fig.add_trace(go.Scatter(\n",
        "    #             x=historical['forecast_timestamp'],\n",
        "    #             y=historical['revenue_millions'],\n",
        "    #             mode='lines+markers',\n",
        "    #             name=f'{company} (Historical)',\n",
        "    #             line=dict(color=color, width=3),\n",
        "    #             legendgroup=company\n",
        "    #         ))\n",
        "\n",
        "    #         # Forecast line\n",
        "    #         fig.add_trace(go.Scatter(\n",
        "    #             x=forecast['forecast_timestamp'],\n",
        "    #             y=forecast['forecast_value'],\n",
        "    #             mode='lines+markers',\n",
        "    #             name=f'{company} (Forecast)',\n",
        "    #             line=dict(color=color, dash='dash', width=2),\n",
        "    #             legendgroup=company\n",
        "    #         ))\n",
        "\n",
        "    #         # Confidence intervals\n",
        "    #         fig.add_trace(go.Scatter(\n",
        "    #             x=forecast['forecast_timestamp'],\n",
        "    #             y=forecast['prediction_interval_upper_bound'],\n",
        "    #             mode='lines',\n",
        "    #             line=dict(width=0),\n",
        "    #             showlegend=False,\n",
        "    #             legendgroup=company\n",
        "    #         ))\n",
        "\n",
        "    #         fig.add_trace(go.Scatter(\n",
        "    #             x=forecast['forecast_timestamp'],\n",
        "    #             y=forecast['prediction_interval_lower_bound'],\n",
        "    #             mode='lines',\n",
        "    #             fill='tonexty',\n",
        "    #             fillcolor=f'rgba({color[4:-1]}, 0.2)',\n",
        "    #             line=dict(width=0),\n",
        "    #             name=f'{company} (95% CI)',\n",
        "    #             showlegend=False,\n",
        "    #             legendgroup=company\n",
        "    #         ))\n",
        "\n",
        "    #     fig.update_layout(\n",
        "    #         title=\"üöÄ Revenue Forecasting with TimesFM 2.0\",\n",
        "    #         title_x=0.5,\n",
        "    #         title_font_size=20,\n",
        "    #         xaxis_title=\"Year\",\n",
        "    #         yaxis_title=\"Revenue (Millions)\",\n",
        "    #         height=600,\n",
        "    #         hovermode='x unified'\n",
        "    #     )\n",
        "\n",
        "    #     fig.show()\n",
        "\n",
        "    #     print(\"\\nüìà Forecast Summary (Next 5 Years):\")\n",
        "    #     forecast_summary = forecast_df[forecast_df['forecast_timestamp'] > forecast_df['fiscal_year_date'].max()]\n",
        "    #     for company in companies:\n",
        "    #         company_forecast = forecast_summary[forecast_summary['company_name_formatted'] == company]\n",
        "    #         if not company_forecast.empty:\n",
        "    #             avg_growth = company_forecast['forecast_value'].mean()\n",
        "    #             print(f\"{company}: Average forecasted revenue: ${avg_growth:.1f}M\")\n",
        "\n",
        "    # else:\n",
        "    #     print(\"‚ö†Ô∏è  No forecast data generated\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Forecasting issue: {e}\")"
      ],
      "metadata": {
        "id": "K0Ut1XBtZ3Gn",
        "outputId": "74258e63-327f-43f4-bfcc-66777e646125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "id": "K0Ut1XBtZ3Gn",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÆ Generating revenue forecasts with TimesFM 2.0...\n",
            "‚è≥ Forecasting...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 Unrecognized name: revenue_millions at [15:7]; reason: invalidQuery, location: query, message: Unrecognized name: revenue_millions at [15:7]\n\nLocation: US\nJob ID: 95efd828-859f-4dd4-9d24-66b9755f7941\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1378309275.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚è≥ Forecasting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Forecast table created successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1704\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1706\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1707\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1653\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 Unrecognized name: revenue_millions at [15:7]; reason: invalidQuery, location: query, message: Unrecognized name: revenue_millions at [15:7]\n\nLocation: US\nJob ID: 95efd828-859f-4dd4-9d24-66b9755f7941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# from google.cloud import bigquery\n",
        "\n",
        "# PROJECT_ID = \"intellitrend-project-dev\"   # update if needed\n",
        "# DATASET_ID = \"db_reports_insights_annual_esg\"\n",
        "# TABLE_ID = \"all_reports_annual_esg\"\n",
        "\n",
        "# # Step 0: Fetch file list from GitHub\n",
        "# url = \"https://api.github.com/repos/intellitrend-global/google_hackathon_bq_ai/contents/annual_esg_reports\"\n",
        "# response = requests.get(url)\n",
        "# files = response.json()\n",
        "\n",
        "# pdf_files = [(f[\"name\"], f[\"download_url\"]) for f in files if f[\"name\"].endswith(\".pdf\")]\n",
        "\n",
        "# print(\"üìÑ Found PDF files on GitHub:\")\n",
        "# for name, link in pdf_files:\n",
        "#     print(f\"   {name} -> {link}\")\n",
        "\n",
        "# # Step 1: Initialize BigQuery client\n",
        "# client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# # Step 2: Ensure dataset exists (create if not)\n",
        "# dataset_ref = bigquery.DatasetReference(PROJECT_ID, DATASET_ID)\n",
        "# try:\n",
        "#     client.get_dataset(dataset_ref)  # Check if it exists\n",
        "#     print(f\"‚úÖ Dataset {DATASET_ID} already exists\")\n",
        "# except Exception:\n",
        "#     dataset = bigquery.Dataset(dataset_ref)\n",
        "#     dataset.location = \"US\"\n",
        "#     client.create_dataset(dataset, timeout=30)\n",
        "#     print(f\"üì¶ Created dataset {DATASET_ID}\")\n",
        "\n",
        "# # Step 3: Define schema\n",
        "# schema = [\n",
        "#     bigquery.SchemaField(\"filename\", \"STRING\"),\n",
        "#     bigquery.SchemaField(\"uri\", \"STRING\"),\n",
        "# ]\n",
        "\n",
        "# # Step 4: Prepare rows\n",
        "# rows = [{\"filename\": name, \"uri\": link} for name, link in pdf_files]\n",
        "\n",
        "# # Step 5: Load into BigQuery\n",
        "# job_config = bigquery.LoadJobConfig(schema=schema, write_disposition=\"WRITE_TRUNCATE\")\n",
        "# table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# job = client.load_table_from_json(rows, table_ref, job_config=job_config)\n",
        "# job.result()\n",
        "\n",
        "# print(f\"‚úÖ Table {table_ref} created/updated with {len(pdf_files)} GitHub files\")\n"
      ],
      "metadata": {
        "id": "xNskNaElWO_1"
      },
      "id": "xNskNaElWO_1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}